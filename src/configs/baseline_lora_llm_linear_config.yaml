name: "lora_llm_linear_baseline"

model:
  model_name: "unsloth/Qwen3-8B-Base-unsloth-bnb-4bit"
  # For evaluation: load base from this path. Use model_name so we get base+LoRA structure
  # (base loads from HF, then LoRA is applied). Classifier weights loaded from model_checkpoint.
  pretrained_checkpoint: "unsloth/Qwen3-8B-Base-unsloth-bnb-4bit"
  max_length: 12000
  hidden_size: 4096
  num_labels: 2
  head_type: "linear"
  head_hidden_size: 512
  head_dropout: 0.1

lora:
  r: 16
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
  lora_alpha: 32
  lora_dropout: 0.05
  bias: "none"
  use_rslora: true

wandb:
  enabled: true
  project: "Pretrain-Qwen3-8B-Pancreas-classification"
  run_name: "baseline-lora-llm-linear"

training:
  output_dir: "/data/scratch/qc25022/pancreas_MEDS/experiments/baselines/lora_llm_linear"
  overwrite_output_dir: true
  epochs: 2
  batch_size: 2
  eval_batch_size: 2
  learning_rate: 1e-5
  weight_decay: 0.01
  warmup_steps: 100
  gradient_accumulation_steps: 2
  fp16: false
  bf16: true
  logging_steps: 50
  eval_steps: 250
  save_steps: 500
  save_total_limit: 2
  load_in_4bit: true
  multi_label: false
  dataloader_num_workers: 2
  gradient_checkpointing: "unsloth"

data:
  cutoff_months: 6
  data_dir: "/data/scratch/qc25022/pancreas/tokenised_data_pancreas_MEDS/cprd_upgi"
  vocab_filepath: "/data/scratch/qc25022/pancreas/tokenised_data_pancreas_MEDS/cprd_upgi/vocab.csv"
  labels_filepath: "/data/home/qc25022/cancer-extraction-pipeline/output/pancreas_MEDS/subject_information.csv"
  medical_lookup_filepath: "/data/home/qc25022/TextCancEHR2/src/resources/MedicalDictTranslation2.csv"
  lab_lookup_filepath: "/data/home/qc25022/TextCancEHR2/src/resources/LabLookUP.csv"
  region_lookup_filepath: "/data/home/qc25022/TextCancEHR2/src/resources/RegionLookUp.csv"
  time_lookup_filepath: "/data/home/qc25022/TextCancEHR2/src/resources/TimeLookUp.csv"
  max_length: 12000
  handle_long_sequences: "warn"
  sort_by_length: true

